---
layout:     post
title:     数据结构与算法（2022.3.31 第二轮 更新）
description:     Project JOB
date:     2022-03-27
author:     POt
header-img:     img/post-bg-kuaidi.jpg
catalog: true
category: blog
tags:     
    -   
        -   

    -   

---
## 哈希表（位桶 + 链表 / 红黑树）

引：

```java
HashMap<String, Integer> map = new HashMap<String, Integer>();
 map.put("语文", 1);
 map.put("数学", 2);
 map.put("英语", 3);
 map.put("历史", 4);
 map.put("政治", 5);
 map.put("地理", 6);
 map.put("生物", 7);
 map.put("化学", 8);
for(Entry<String, Integer> entry : map.entrySet()) {
    System.out.println(entry.getKey() + ": " + entry.getValue());
}
```

运行结果：政治: 5 生物: 7 历史: 4 数学: 2 化学: 8 语文: 1 英语: 3 地理: 6**（其实是有序存储的）**

![](https://s2.loli.net/2022/03/26/a65mTShgwWcCAbj.png)

### HashMap中两个重要参数

![](https://s2.loli.net/2022/03/26/AtxzjJ5iOvb4oly.png)

在HashMap中有两个很重要的参数，**容量(Capacity)**和**负载因子(Load factor)**

简单的说，**Capacity就是buckets的数目**，**Load factor就是buckets填满程度的最大比例**。如果对迭代性能要求很高的话不要把`capacity`设置过大，也不要把`load factor`设置过小。**当bucket填充的数目（即hashmap中元素的个数）大于`capacity*load factor`时就需要调整buckets的数目为当前的2倍。**

### put()函数的实现

put函数大致的思路为：

1. 对**key**的hashCode()**做hash**，然后再**计算index**;
2. 如果**没碰撞直接放到bucket里**；
3. 如果碰撞了，**以链表的形式存在buckets后**；
4. **如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)（树化门限值），就把链表转换成红黑树；**
5. **如果节点已经存在就替换old value(保证key的唯一性)**
6. **如果bucket满了(超过load factor*current capacity)，就要resize。**

#### hash函数的实现

在get和put的过程中，计算下标时，先调用HashCode方法进行hash操作，然后再通过hash值进一步计算下标，如下图所示

![](https://s2.loli.net/2022/03/26/2PM4BhbN173WoIu.png)

计算HashCode()：可以看到这个函数大概的作用就是：**高16bit不变，低16bit和高16bit做了一个或运算。**（异或：**不同为1，相同为0**）

计算index()：**HashCode与n-1进行与运算**（与运算：**相同为1，不同为0**），如上图所示，上图为HashCode与15（16 - 1，二进制1111）进行与运算，得出index值为0101 = 5

#### 如何获取HashMap元素？

在获取HashMap的元素时，基本分两步：

1. 首先根据hashCode()做hash，然后确定bucket的index；
2. 如果bucket的节点的key不是我们需要的，则通过keys.equals()在链中找。

### get()函数的实现

1. 如果无冲突，bucket里的第一个节点，直接命中；
2. 如果有冲突，则通过key.equals(k)去查找对应的entry 若为树，则在**树中通过key.equals(k)查找**，**O(logn)**； 若为链表，则**在链表中通过key.equals(k)查找，O(n)**。

### 扩容的实现

当**put**时，如果发现**目前的bucket占用程度已经超过了Load Factor所希望的比例，那么就会发生resize**。在resize的过程，简单的说就是**把bucket扩充为2倍（二进制扩充四位）**，**之后重新计算index**，**把节点再放到新的bucket中**。

注：经过演算，**在扩充HashMap的时候，需要重新调用HashCode()，不需要重新计算hash，只需要看看原来的hashCode新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCapacity”。**

### 什么时候会使用HashMap？他有什么特点？

是**基于Map接口的实现**，**存储键值对**时，它可以接收null的键值，**是非同步的**，HashMap存储着Entry（hash, key value, next），基于Map.Entry的对象

### 你知道HashMap的工作原理吗？

通过hash的方法，通过get和put存储对象、存储对象时，将Key和Value传给put方法时，它调用HashCode方法计算Key的Hash值，再通过算法计算index值，检查是否产生冲突，不冲突放入Bucket，冲突则放入Bucket后的链表，若链表的长度大于树化门限值（默认为8），则将链表转为红黑树。HashMap会根据当前Bucket的使用情况来动态调整，若当前占用大小大于Capacity * Load Factor 则进行扩容，扩容大小为原来的两倍（2次幂的扩展）。

### 你知道get和put的原理吗？equals()和hashCode()的都有什么作用？

![](https://img-blog.csdnimg.cn/img_convert/330b7cc136e1e6fa8d6a2677680be0d0.png)

* get()：

  对key元素做Hash运算，得到Hash值并计算下标index( n-1 & hash)，检查Bucket，若不产生碰撞则直接读取，若碰撞则在链表O(n) / 红黑树O(log(n))中遍历调用key.equals()进行值对比

* put()

  对Key值调用HashCode()方法做Hash运算，在对Hash值（高16bit不变，低16bit与高16bit做异或运算）进行index计算，若不碰撞，则放入Bucket，若碰撞则放入Bucket后的链表 / 红黑树。若Bucket中占用的容量大于Capacity * Load Factor，则进行扩容（为原来的2倍，2次幂扩展），若链表长度大于树化门限值（默认为8），则将链表转为红黑树

### 你知道hash的实现吗？为什么要这样实现？

在Java1.8的实现中，是通过高16位与低16位异或得到的hash值，主要是从速度、功效、质量来考虑的，这么做**可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销。**（保证每一位都能参与到运算，不会孤立其他的位）

### 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？

如果超过了负载因子(默认0.75)，则会重新resize一个原来长度两倍的HashMap，并且重新调用hash方法。

### 负载因子为什么要设置为0.75？

HashMap基于链表的数组的数据结构实现的

我们在向HashMap中put元素的时候，就需要先定外到是数组中的哪条链表，然后把这个元素挂在这个链表的后面。

当**我们从HashMap中get元素的时候，也是需要定位到是数组中的哪条链表，然后再逐一遍历链表中的元素，直到查找到需要的元素为止**。

可见，HashMap通过链表的数组这种结构，解决了hash冲突的问题。

但是，如**果一个HashMap中冲突太高，那么数组的链表就会退化为链表。这时候查询速度会大大降低**。

那么，为什么选择0.75呢？背后有什么考虑？为什么不是1，不是0.8？不是0.5，而是0.75呢？

在JDK的官方文档中，有这样一段描述描述：

> As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put).

大概意思是：一般来说，默认的负载因子(0.75)在时间和空间成本之间提供了很好的权衡。更高的值减少了空间开销，但增加了查找成本(反映在HashMap类的大多数操作中，包括get和put)。

那么在HashMap中，最好的情况是这16个元素通过hash算法之后分别落到了16个不同的桶中，否则就必然发生哈希碰撞。而且随着元素越多（因为是HashCode和 n - 1做与运算），哈希碰撞的概率越大，查找速度也会越低。

那么，为了保证`负载因子（loadFactor） * 容量（capacity）`的结果是一个整数，这个值是0.75(3/4)比较合理，**因为这个数和任何2的幂乘积结果都是整数**。

### 如何实现一个并发安全的 HashMap？

1. 检测：例如 Java 的 `HashMap` 类型，使用了 fail-fast 机制，记录 `modCount` 表示哈希表的修改次数。在一个线程访问一个 map 前，会先记录 `modCount` 的旧值，然后在访问过程中比较旧值和当前值，如果不相等说明有其他线程修改了这个 map，于是**抛出异常**。*可以理解为乐观锁。*
2. 锁：例如 Java 的 `HashTable` 类型，结构和 `HashMap` 类似，唯独在接口上使用了 `synchronized` 修饰符，保证抢占到内置锁之后才会执行。*可以理解为悲观所，线程竞争激烈的情况下，效率低下。*
3. 分段锁：例如 Java 的 `ConcurrentHashMap` 类型。分段锁，顾名思义就是将锁分段，将锁的粒度变小，将存储的对象分散到各个分片中，每个分片由一把锁控制，这样使得当需要对在 A 分片上的数据进行读写时不会影响 B 分片的读写，从而提高并发度。

## 排序算法

![](https://s2.loli.net/2022/03/27/NaLn7ieV1gkEpKZ.png)

![](https://s2.loli.net/2022/03/27/v97sHP1t8zLB5u2.png)

### 冒泡排序

i 表示已经排序的元素，排完 n-1 个后最后一个也不需要排了O(n2)

```java
public int[] sortArray(int[] nums) {
        int n = nums.length;
        for(int i = 0; i < n; i++){
            for(int j = 1; j < n - i; j++){
                if(nums[j - 1] > nums[j]){
                    int temp = nums[j - 1];
                    nums[j - 1] = nums[j];
                    nums[j] = temp;
                }
            }
        }
        return nums;
    }
```

### 插入排序

```java
public int[] sortArray(int[] nums) {
        int n = nums.length;
        for(int i = 1; i < n; i++){
            int j = i - 1;
            int key = nums[i];
            while(j >= 0 && key < nums[j]){
                int temp = nums[j + 1];
                nums[j + 1] = nums[j];
                nums[j] = temp;
                j--; 
            }
            nums[j + 1] = key;
        }
        return nums;
    }
```



### 快速排序

```java
void quickSort(int[] arr, int low, int high){
        if(low >= high){
            return;
        }
        int left = low;
        int right = high;
        int pivot = arr[left];
        while(left < right){
            while(left < right && pivot <= arr[right]){
                right--;
            }
            arr[left] = arr[right];
            while(left < right && pivot >= arr[left]){
                left++;
            }
            arr[right] = arr[left];
        }
        arr[left] = pivot;
        quickSort(arr, low, left - 1);
        quickSort(arr, left + 1, high);
    }
```

## 堆排序

#### 前言

堆是一种非线性结构，可以把堆看作一个**数组**，也可以被看作一个**完全二叉树**，通俗来讲堆其实就是利用**完全二叉树的结构来维护的一维数组**但堆并不一定是完全二叉树

按照堆的特点可以把堆分为**大顶堆**和**小顶堆**
**大顶堆**：每个结点的值都**大于或等于**其左右孩子结点的值
**小顶堆**：每个结点的值都**小于或等于**其左右孩子结点的值

#### 使用堆的原因

如果仅仅是需要得到一个有序的序列，使用排序就可以很快完成，并不需要去组织一个新的数据结构。但是如果我们的**需求是对于一个随时会有更新的序列**，我要**随时知道这个序列的最小值或最大值是什么**。假设原数组是有序的，那使用二分把它放在正确的位置也未尝不可，但是插入的时候从数组中留出空位就需要**O(n)**的时间复杂度，删除的时候亦然。

**可是如果我们将序列看作是一个集合，我们需要的是这个集合的一个最小值或者最大值**，并且，在它被任意划分成为若干个子集的时候，这些子集的最小值或者最大值我们也是知道的，这些子集被不断划分，我们依然知道这些再次被划分出来的子集的最小值或者最大值。

#### 堆的特点

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dGliOGNDQm9LNHhoMTd2dWF6VVhZTVRHU3RIMmtJS0k1Y0s2ZlNaNzFlODBSa3ZGMG0ydW9JOFEvNjQw?x-oss-process=image/format,png)

![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dGNSVGlibDFlTUswN1gwRlJCWlNpYWdYNjRqMlNmSzVHZ3NpY0lHTlN3d0l2VHM1T0VKeEVpYXFGRkEvNjQw?x-oss-process=image/format,png)

大顶堆 arr : `50 45 40 20 25 35 30 10 15`
小顶堆 arr : `10 20 15 25 50 30 40 35 45`

#### 堆和普通树的区别

普通树占用的内存空间比它们存储的数据要多。你必须为节点对象以及左/右子节点指针分配额外的内存。**堆仅仅使用数组，且不使用指针**

#### 时间复杂度

**O(nlog2n)**

#### 举例构建堆排序

1. 给一个无序序列

   int a[6] = {7, 3, 8, 5, 1, 2}

2. **根据数组将完全二叉树还原出来**

   ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dG5vaWFWQTJEWGRJWXNTS0Vtc09EeFlmdnFkRUlVN21ISzR2UjBFT0o1cEZUYVZ3WUo5WmY5ZGcvNjQw?x-oss-process=image/format,png)

   现在我们要做的事情就是要把`7，3，8，5，1，2`变成一个有序的序列，如果想要升序就是`1，2，3，5，7，8`如果想要降序就是`8，7，5，3，2，1`这两种就是我们要的最终结果，然后我们就可以根据我们想要的结果来选择
   适合类型的堆来进行排序

   * 升序：大顶堆
   * 降序：小顶堆

3. 为什么升序要用大顶堆呢

   大顶堆的特点：每个结点的值都大于等于子节点的值，把大大顶堆构建完毕后根节点的值一定是最大的。然后**把根节点和最后一个元素**（也可以说最后一个节点）交换位置，**那么末尾元素此时就是最大元素了**

4. 图解交换过程

   先找到最后一个非叶子节点：**长度 / 2 - 1**，然后下一步比较该节点值和它的子树值，如果该节点小于其左 / 右子树值就交换（将最大的值放在节点上）

   ![8只有一个左子树，左子树值为2，不用交换](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dGVoUkgzYVA4WWdiUnBBVUVOa2E4WmR2Y2liVjJndWliaWFpYVdzWGhrM1M5ZjBjU2hnUjZnUUQyN2cvNjQw?x-oss-process=image/format,png)

   下一步，找到下一个非叶子节点，即坐标减1，2-1=1，该节点的值为3，小于左子树5，交换，交换后该节点值为5，大于右子树值1，不需要交换。

   ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dE9uSGd3aWJSaWJhMmZjc0hIOTQxNVZQZkFHTkthaWJRV3k2RHBMQkRPdnl2RDZ5ZlBmaFNOWFhJZy82NDA?x-oss-process=image/format,png)

   ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dFFYdktwc21GT1Jld1BKek9QUkRDWVR1SEtJVngyZGdpYVoxWnBodVpHUWliRzBoSlRXZlhINm1BLzY0MA?x-oss-process=image/format,png)

   下一步，找到下一个非叶子节点1 - 1 = 0，该节点的值为7，大于左子树的值，不用交换；小于右子树的值，进行交换

   ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dENsaWJlMnhvaWMwd3Z2aWNpY2lhZllMQzRiQzNyU2IxelczWEZSMmtwV3BUYVJFOTZMTkMzanlXVWJ3LzY0MA?x-oss-process=image/format,png)

   ![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6L1NpYjNOdHZ2aDJiU3ZmdEtvVDRMRW1CdkY0M3FqVDZ6dHY2RDZLTmJpYmpzZUVFOWw3ZWM0eEJTMDBpYlIxdDVmWG9MQTVseTFCYjduaWJ0cUJWRXcwdTRVZy82NDA?x-oss-process=image/format,png)

   下一步，检查调整后的子树，是否满足大顶堆性质，如果不满足则继续调整（看交换后的节点“7”还是否满足大顶堆性质），就不需要调整了，如果运气不好整个根节点的值是1

   **这样大顶堆的构建就完成了**

   **然后下一步交换根节点`8`与最后一个元素`2`交换位置**（将最大元素"沉"到数组末端），此时最大的元素就归位了。此时，再检查其余节点是否符合大顶堆性质，不符合继续调整，将根节点与导数第二个元素交换，然后对剩下的5个元素重复上面的操作。最后得到升序序列

5. 堆排序的代码实现

   ```
   
   public static void heapSort(int[] arr) {
   		if (arr == null || arr.length == 0) {
   			return;
   		}
   		int len = arr.length;
   		// 构建大顶堆，这里其实就是把待排序序列，变成一个大顶堆结构的数组
   		buildMaxHeap(arr, len);
    
   		// 交换堆顶和当前末尾的节点，重置大顶堆
   		for (int i = len - 1; i > 0; i--) {
   			swap(arr, 0, i);
   			len--;
   			heapify(arr, 0, len);
   		}
   	}
    
   	private static void buildMaxHeap(int[] arr, int len) {
   		// 从最后一个非叶节点开始向前遍历，调整节点性质，使之成为大顶堆
   		for (int i = (int)Math.floor(len / 2) - 1; i >= 0; i--) {
   			heapify(arr, i, len);
   		}
   	}
    
   	private static void heapify(int[] arr, int i, int len) {
   		// 先根据堆性质，找出它左右节点的索引
   		int left = 2 * i + 1;
   		int right = 2 * i + 2;
   		// 默认当前节点（父节点）是最大值。
   		int largestIndex = i;
   		if (left < len && arr[left] > arr[largestIndex]) {
   			// 如果有左节点，并且左节点的值更大，更新最大值的索引
   			largestIndex = left;
   		}
   		if (right < len && arr[right] > arr[largestIndex]) {
   			// 如果有右节点，并且右节点的值更大，更新最大值的索引
   			largestIndex = right;
   		}
    
   		if (largestIndex != i) {
   			// 如果最大值不是当前非叶子节点的值，那么就把当前节点和最大值的子节点值互换
   			swap(arr, i, largestIndex);
   			// 因为互换之后，子节点的值变了，如果该子节点也有自己的子节点，仍需要再次调整。
   			heapify(arr, largestIndex, len);
   		}
   	}
    
   	private static void swap (int[] arr, int i, int j) {
   		int temp = arr[i];
   		arr[i] = arr[j];
   		arr[j] = temp;
   	}
   ```
   
   

感谢以下作者：

[为什么LoadFactor不设为1](https://juejin.cn/post/6844904070923157517#heading-4)

[Java HashMap工作原理及实现](https://cloud.tencent.com/developer/article/1167574)

[技术面试题汇总](https://imageslr.com/2020/07/08/tech-interview.html)

[谈谈堆排序，大顶堆，小顶堆](https://blog.csdn.net/qq_34629352/article/details/105601080)
